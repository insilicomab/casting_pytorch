{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "casting_pytorch_test_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "apSh6D4Wl1u5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "481a9065-9a48-4f3b-d79c-5fbaf4ee0081"
      },
      "source": [
        "!pip install signate\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'signate.json'\", fields=\"files(id)\").execute()\n",
        "signate_api_key = results.get('files', [])\n",
        "\n",
        "filename = \"/root/.signate/signate.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "request = drive_service.files().get_media(fileId=signate_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting signate\n",
            "  Downloading signate-0.9.9-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from signate) (7.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from signate) (2021.10.8)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Collecting urllib3>=1.26.7\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 13.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from signate) (0.8.9)\n",
            "Collecting six>=1.16\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from signate) (2.8.2)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=f3ea20f2f9ca696dddab8e24a95be560fca8754dfc52fb72015a4844db934ea6\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: six, wget, urllib3, signate\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.8 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed signate-0.9.9 six-1.16.0 urllib3-1.26.8 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download 100%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra23e3pFnBLd",
        "outputId": "8ca3cba8-8a9e-4f70-8610-a5f45290a82b"
      },
      "source": [
        "! signate list \n",
        "! signate files --competition-id=406\n",
        "! signate download --competition-id=406"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  competitionId  title                                                                                      closing     prize                  submitters\n",
            "---------------  -----------------------------------------------------------------------------------------  ----------  -------------------  ------------\n",
            "              1  【練習問題】銀行の顧客ターゲティング                                                       -                                        5396\n",
            "             24  【練習問題】お弁当の需要予測                                                               -                                        6663\n",
            "             27  【練習問題】Jリーグの観客動員数予測                                                        -                                        1527\n",
            "            100  【練習問題】手書き文字認識                                                                 -           Knowledge                     204\n",
            "            102  【練習問題】タイタニックの生存予測                                                         -           Knowledge                    1259\n",
            "            103  【練習問題】音楽ラベリング                                                                 -           Knowledge                      62\n",
            "            104  【練習問題】スパムメール分類                                                               -           Knowledge                     135\n",
            "            105  【練習問題】毒キノコの分類                                                                 -           Knowledge                     267\n",
            "            106  【練習問題】アワビの年齢予測                                                               -           Knowledge                     363\n",
            "            107  【練習問題】国勢調査からの収入予測                                                         -           Knowledge                     543\n",
            "            108  【練習問題】画像ラベリング（20種類）                                                       -           Knowledge                     226\n",
            "            112  【練習問題】ワインの品種の予測                                                             -           Knowledge                     314\n",
            "            113  【練習問題】山火事の消失面積予測                                                           -           Knowledge                     203\n",
            "            114  【練習問題】レンタル自転車の利用者数予測                                                   -           Knowledge                     385\n",
            "            115  【練習問題】アヤメの分類                                                                   -           Knowledge                     355\n",
            "            116  【練習問題】活動センサーログからの動作予測                                                 -           Knowledge                      50\n",
            "            118  【練習問題】テニスの試合結果の予測                                                         -           Knowledge                     124\n",
            "            121  【練習問題】自動車の走行距離予測                                                           -           Knowledge                    1461\n",
            "            122  【練習問題】自動車の評価                                                                   -           Knowledge                     315\n",
            "            123  【練習問題】オゾンレベルの分類                                                             -           Knowledge                      45\n",
            "            124  【練習問題】ボットの判別                                                                   -           Knowledge                     303\n",
            "            125  【練習問題】ガラスの分類                                                                   -           Knowledge                     155\n",
            "            126  【練習問題】林型の分類                                                                     -           Knowledge                      39\n",
            "            127  【練習問題】ゲーム選手のリーグ分類                                                         -           Knowledge                      57\n",
            "            128  【練習問題】ステンレス板の欠陥分類                                                         -           Knowledge                      64\n",
            "            129  【練習問題】都市サイクルの燃料消費量予測                                                   -           Knowledge                     123\n",
            "            130  【練習問題】天秤のバランス分類                                                             -           Knowledge                      98\n",
            "            132  【練習問題】ネット広告のクリック予測                                                       -           Knowledge                     143\n",
            "            133  【練習問題】画像ラベリング（10種類）                                                       -                                         348\n",
            "            135  【練習問題】ネット画像の分類                                                               -                                          74\n",
            "            262  【SOTA】国立国会図書館の画像データレイアウト認識                                           2100-12-31  -                              72\n",
            "            263  【SOTA】産業技術総合研究所 衛星画像分析コンテスト                                          2100-12-31  -                              44\n",
            "            264  【SOTA】マイナビ × SIGNATE Student Cup 2019: 賃貸物件の家賃予測                            2100-12-31  -                             366\n",
            "            265  【練習問題】健診データによる肝疾患判定                                                     -                                         507\n",
            "            266  【練習問題】民泊サービスの宿泊価格予測                                                     -                                         573\n",
            "            267  【SOTA】海洋研究開発機構 熱帯低気圧（台風等）検出アルゴリズム作成                          2100-12-31  -                              17\n",
            "            268  【SOTA】オプト レコメンドエンジン作成                                                      2100-12-31                                 34\n",
            "            269  【SOTA】アップル 引越し需要予測                                                            2100-12-31  -                             326\n",
            "            270  【SOTA】Weather Challenge：雲画像予測                                                      2100-12-31  -                               7\n",
            "            271  【SOTA】JR西日本 走行中の北陸新幹線車両台車部の着雪量予測                                  2100-12-31  -                              20\n",
            "            288  【SOTA】Sansan 名刺の項目予測                                                              2100-12-31  -                              30\n",
            "            294  【練習問題】債務不履行リスクの低減                                                         -                                         189\n",
            "            358  【練習問題】機械稼働音の異常検知                                                           -                                          72\n",
            "            404  【練習問題】モノクロ顔画像の感情分類                                                       -                                          76\n",
            "            406  【練習問題】鋳造製品の欠陥検出                                                             -                                         188\n",
            "            409  【練習問題】株価の推移予測                                                                 -                                         174\n",
            "            489  【AIQuest2021】PBL_01 需要予測・在庫最適化（小売業）ビジネス導入課題①                      2022-02-05                                521\n",
            "            490  【AIQuest2021】PBL_01 需要予測・在庫最適化（小売業）ビジネス導入課題②                      2022-02-05                                518\n",
            "            491  【AIQuest2021】PBL_01 需要予測・在庫最適化（小売業）ビジネス導入課題③                      2022-02-05                                517\n",
            "            492  【AIQuest2021】PBL_01 需要予測・在庫最適化（小売業）AI課題                                 2022-02-05                                482\n",
            "            493  【AIQuest2021】PBL_01 需要予測・在庫最適化（小売業）ビジネス実装課題                       2022-02-05                                369\n",
            "            517  【AIQuest2021】PBL_05 不良個所自動検出による検品作業効率化（木材加工業）ビジネス導入課題①  2022-02-05                                149\n",
            "            518  【AIQuest2021】PBL_05 不良個所自動検出による検品作業効率化（木材加工業）ビジネス導入課題②  2022-02-05                                149\n",
            "            519  【AIQuest2021】PBL_05 不良個所自動検出による検品作業効率化（木材加工業）ビジネス導入課題③  2022-02-05                                149\n",
            "            520  【AIQuest2021】PBL_05 不良個所自動検出による検品作業効率化（木材加工業）AI課題             2022-02-05                                134\n",
            "            521  【AIQuest2021】PBL_05 不良個所自動検出による検品作業効率化（木材加工業）ビジネス実装課題   2022-02-05                                 94\n",
            "            537  第5回AIエッジコンテスト（実装コンテスト③）                                                 2022-02-15  total 1,600,000 yen            12\n",
            "            563  SUBARU 画像認識チャレンジ                                                                  2022-01-31  総額¥2,000,000                107\n",
            "            565  【SOTA】SIGNATE Student Cup 2021春：楽曲のジャンル推定チャレンジ！！                       2100-12-31  -                              26\n",
            "            567  【SOTA】SIGNATE Student Cup 2021秋：オペレーション最適化に向けたシェアサイクルの利用予測   2100-12-31  -                              20\n",
            "  fileId  name                   title                                size  updated_at\n",
            "--------  ---------------------  --------------------------------  -------  -------------------\n",
            "    1536  train_data.zip         学習用画像データ                  2533668  2020-12-04 18:06:22\n",
            "    1537  test_data.zip          評価用画像データ                  1006514  2020-12-04 18:07:43\n",
            "    1538  train.csv              学習用画像データとラベルの対応表     5415  2020-12-04 18:08:30\n",
            "    1539  sample_submission.csv  応募用サンプルファイル               1392  2020-12-04 18:08:53\n",
            "sample_submission.csv\n",
            "\n",
            "train.csv\n",
            "\n",
            "test_data.zip\n",
            "\n",
            "train_data.zip\n",
            "\n",
            "\u001b[32m\n",
            "Download completed.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppte1Yvpn2mn",
        "outputId": "08c3b3ee-74a0-44aa-d288-edcfbd6a6905"
      },
      "source": [
        "! unzip test_data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  test_data.zip\n",
            "   creating: test_data/\n",
            "  inflating: test_data/789907.jpeg   \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/test_data/\n",
            "  inflating: __MACOSX/test_data/._789907.jpeg  \n",
            "  inflating: test_data/439948.jpeg   \n",
            "  inflating: __MACOSX/test_data/._439948.jpeg  \n",
            "  inflating: test_data/489913.jpeg   \n",
            "  inflating: __MACOSX/test_data/._489913.jpeg  \n",
            "  inflating: test_data/429933.jpeg   \n",
            "  inflating: __MACOSX/test_data/._429933.jpeg  \n",
            "  inflating: test_data/499929.jpeg   \n",
            "  inflating: __MACOSX/test_data/._499929.jpeg  \n",
            "  inflating: test_data/259831.jpeg   \n",
            "  inflating: __MACOSX/test_data/._259831.jpeg  \n",
            "  inflating: test_data/649971.jpeg   \n",
            "  inflating: __MACOSX/test_data/._649971.jpeg  \n",
            "  inflating: test_data/729911.jpeg   \n",
            "  inflating: __MACOSX/test_data/._729911.jpeg  \n",
            "  inflating: test_data/1009937.jpeg  \n",
            "  inflating: __MACOSX/test_data/._1009937.jpeg  \n",
            "  inflating: test_data/249889.jpeg   \n",
            "  inflating: __MACOSX/test_data/._249889.jpeg  \n",
            "  inflating: test_data/299953.jpeg   \n",
            "  inflating: __MACOSX/test_data/._299953.jpeg  \n",
            "  inflating: test_data/909994.jpeg   \n",
            "  inflating: __MACOSX/test_data/._909994.jpeg  \n",
            "  inflating: test_data/739881.jpeg   \n",
            "  inflating: __MACOSX/test_data/._739881.jpeg  \n",
            "  inflating: test_data/289969.jpeg   \n",
            "  inflating: __MACOSX/test_data/._289969.jpeg  \n",
            "  inflating: test_data/109996.jpeg   \n",
            "  inflating: __MACOSX/test_data/._109996.jpeg  \n",
            "  inflating: test_data/29934.jpeg    \n",
            "  inflating: __MACOSX/test_data/._29934.jpeg  \n",
            "  inflating: test_data/119892.jpeg   \n",
            "  inflating: __MACOSX/test_data/._119892.jpeg  \n",
            "  inflating: test_data/919995.jpeg   \n",
            "  inflating: __MACOSX/test_data/._919995.jpeg  \n",
            "  inflating: test_data/39826.jpeg    \n",
            "  inflating: __MACOSX/test_data/._39826.jpeg  \n",
            "  inflating: test_data/659835.jpeg   \n",
            "  inflating: __MACOSX/test_data/._659835.jpeg  \n",
            "  inflating: test_data/99851.jpeg    \n",
            "  inflating: __MACOSX/test_data/._99851.jpeg  \n",
            "  inflating: test_data/89914.jpeg    \n",
            "  inflating: __MACOSX/test_data/._89914.jpeg  \n",
            "  inflating: test_data/869957.jpeg   \n",
            "  inflating: __MACOSX/test_data/._869957.jpeg  \n",
            "  inflating: test_data/879941.jpeg   \n",
            "  inflating: __MACOSX/test_data/._879941.jpeg  \n",
            "  inflating: test_data/349836.jpeg   \n",
            "  inflating: __MACOSX/test_data/._349836.jpeg  \n",
            "  inflating: test_data/359973.jpeg   \n",
            "  inflating: __MACOSX/test_data/._359973.jpeg  \n",
            "  inflating: test_data/389908.jpeg   \n",
            "  inflating: __MACOSX/test_data/._389908.jpeg  \n",
            "  inflating: test_data/49888.jpeg    \n",
            "  inflating: __MACOSX/test_data/._49888.jpeg  \n",
            "  inflating: test_data/979891.jpeg   \n",
            "  inflating: __MACOSX/test_data/._979891.jpeg  \n",
            "  inflating: test_data/969983.jpeg   \n",
            "  inflating: __MACOSX/test_data/._969983.jpeg  \n",
            "  inflating: test_data/329953.jpeg   \n",
            "  inflating: __MACOSX/test_data/._329953.jpeg  \n",
            "  inflating: test_data/819873.jpeg   \n",
            "  inflating: __MACOSX/test_data/._819873.jpeg  \n",
            "  inflating: test_data/59918.jpeg    \n",
            "  inflating: __MACOSX/test_data/._59918.jpeg  \n",
            "  inflating: test_data/399924.jpeg   \n",
            "  inflating: __MACOSX/test_data/._399924.jpeg  \n",
            "  inflating: test_data/339986.jpeg   \n",
            "  inflating: __MACOSX/test_data/._339986.jpeg  \n",
            "  inflating: test_data/809920.jpeg   \n",
            "  inflating: __MACOSX/test_data/._809920.jpeg  \n",
            "  inflating: test_data/699970.jpeg   \n",
            "  inflating: __MACOSX/test_data/._699970.jpeg  \n",
            "  inflating: test_data/689927.jpeg   \n",
            "  inflating: __MACOSX/test_data/._689927.jpeg  \n",
            "  inflating: test_data/529883.jpeg   \n",
            "  inflating: __MACOSX/test_data/._529883.jpeg  \n",
            "  inflating: test_data/459909.jpeg   \n",
            "  inflating: __MACOSX/test_data/._459909.jpeg  \n",
            "  inflating: test_data/449821.jpeg   \n",
            "  inflating: __MACOSX/test_data/._449821.jpeg  \n",
            "  inflating: test_data/759854.jpeg   \n",
            "  inflating: __MACOSX/test_data/._759854.jpeg  \n",
            "  inflating: test_data/569906.jpeg   \n",
            "  inflating: __MACOSX/test_data/._569906.jpeg  \n",
            "  inflating: test_data/169903.jpeg   \n",
            "  inflating: __MACOSX/test_data/._169903.jpeg  \n",
            "  inflating: test_data/799977.jpeg   \n",
            "  inflating: __MACOSX/test_data/._799977.jpeg  \n",
            "  inflating: test_data/639930.jpeg   \n",
            "  inflating: __MACOSX/test_data/._639930.jpeg  \n",
            "  inflating: test_data/179915.jpeg   \n",
            "  inflating: __MACOSX/test_data/._179915.jpeg  \n",
            "  inflating: test_data/239962.jpeg   \n",
            "  inflating: __MACOSX/test_data/._239962.jpeg  \n",
            "  inflating: test_data/629822.jpeg   \n",
            "  inflating: __MACOSX/test_data/._629822.jpeg  \n",
            "  inflating: test_data/579910.jpeg   \n",
            "  inflating: __MACOSX/test_data/._579910.jpeg  \n",
            "  inflating: test_data/749878.jpeg   \n",
            "  inflating: __MACOSX/test_data/._749878.jpeg  \n",
            "  inflating: test_data/229958.jpeg   \n",
            "  inflating: __MACOSX/test_data/._229958.jpeg  \n",
            "  inflating: test_data/409965.jpeg   \n",
            "  inflating: __MACOSX/test_data/._409965.jpeg  \n",
            "  inflating: test_data/369861.jpeg   \n",
            "  inflating: __MACOSX/test_data/._369861.jpeg  \n",
            "  inflating: test_data/379924.jpeg   \n",
            "  inflating: __MACOSX/test_data/._379924.jpeg  \n",
            "  inflating: test_data/859982.jpeg   \n",
            "  inflating: __MACOSX/test_data/._859982.jpeg  \n",
            "  inflating: test_data/849890.jpeg   \n",
            "  inflating: __MACOSX/test_data/._849890.jpeg  \n",
            "  inflating: test_data/989921.jpeg   \n",
            "  inflating: __MACOSX/test_data/._989921.jpeg  \n",
            "  inflating: test_data/939891.jpeg   \n",
            "  inflating: __MACOSX/test_data/._939891.jpeg  \n",
            "  inflating: test_data/999921.jpeg   \n",
            "  inflating: __MACOSX/test_data/._999921.jpeg  \n",
            "  inflating: test_data/19871.jpeg    \n",
            "  inflating: __MACOSX/test_data/._19871.jpeg  \n",
            "  inflating: test_data/679931.jpeg   \n",
            "  inflating: __MACOSX/test_data/._679931.jpeg  \n",
            "  inflating: test_data/929917.jpeg   \n",
            "  inflating: __MACOSX/test_data/._929917.jpeg  \n",
            "  inflating: test_data/669862.jpeg   \n",
            "  inflating: __MACOSX/test_data/._669862.jpeg  \n",
            "  inflating: test_data/719946.jpeg   \n",
            "  inflating: __MACOSX/test_data/._719946.jpeg  \n",
            "  inflating: test_data/539843.jpeg   \n",
            "  inflating: __MACOSX/test_data/._539843.jpeg  \n",
            "  inflating: test_data/139981.jpeg   \n",
            "  inflating: __MACOSX/test_data/._139981.jpeg  \n",
            "  inflating: test_data/129893.jpeg   \n",
            "  inflating: __MACOSX/test_data/._129893.jpeg  \n",
            "  inflating: test_data/199935.jpeg   \n",
            "  inflating: __MACOSX/test_data/._199935.jpeg  \n",
            "  inflating: test_data/599930.jpeg   \n",
            "  inflating: __MACOSX/test_data/._599930.jpeg  \n",
            "  inflating: test_data/589947.jpeg   \n",
            "  inflating: __MACOSX/test_data/._589947.jpeg  \n",
            "  inflating: test_data/419909.jpeg   \n",
            "  inflating: __MACOSX/test_data/._419909.jpeg  \n",
            "  inflating: test_data/189978.jpeg   \n",
            "  inflating: __MACOSX/test_data/._189978.jpeg  \n",
            "  inflating: test_data/709966.jpeg   \n",
            "  inflating: __MACOSX/test_data/._709966.jpeg  \n",
            "  inflating: test_data/219889.jpeg   \n",
            "  inflating: __MACOSX/test_data/._219889.jpeg  \n",
            "  inflating: test_data/209923.jpeg   \n",
            "  inflating: __MACOSX/test_data/._209923.jpeg  \n",
            "  inflating: test_data/769946.jpeg   \n",
            "  inflating: __MACOSX/test_data/._769946.jpeg  \n",
            "  inflating: test_data/159915.jpeg   \n",
            "  inflating: __MACOSX/test_data/._159915.jpeg  \n",
            "  inflating: test_data/479840.jpeg   \n",
            "  inflating: __MACOSX/test_data/._479840.jpeg  \n",
            "  inflating: test_data/619967.jpeg   \n",
            "  inflating: __MACOSX/test_data/._619967.jpeg  \n",
            "  inflating: test_data/609988.jpeg   \n",
            "  inflating: __MACOSX/test_data/._609988.jpeg  \n",
            "  inflating: test_data/559880.jpeg   \n",
            "  inflating: __MACOSX/test_data/._559880.jpeg  \n",
            "  inflating: test_data/149997.jpeg   \n",
            "  inflating: __MACOSX/test_data/._149997.jpeg  \n",
            "  inflating: test_data/779897.jpeg   \n",
            "  inflating: __MACOSX/test_data/._779897.jpeg  \n",
            "  inflating: test_data/549992.jpeg   \n",
            "  inflating: __MACOSX/test_data/._549992.jpeg  \n",
            "  inflating: test_data/269945.jpeg   \n",
            "  inflating: __MACOSX/test_data/._269945.jpeg  \n",
            "  inflating: test_data/279912.jpeg   \n",
            "  inflating: __MACOSX/test_data/._279912.jpeg  \n",
            "  inflating: test_data/469837.jpeg   \n",
            "  inflating: __MACOSX/test_data/._469837.jpeg  \n",
            "  inflating: test_data/509856.jpeg   \n",
            "  inflating: __MACOSX/test_data/._509856.jpeg  \n",
            "  inflating: test_data/519895.jpeg   \n",
            "  inflating: __MACOSX/test_data/._519895.jpeg  \n",
            "  inflating: test_data/959829.jpeg   \n",
            "  inflating: __MACOSX/test_data/._959829.jpeg  \n",
            "  inflating: test_data/69975.jpeg    \n",
            "  inflating: __MACOSX/test_data/._69975.jpeg  \n",
            "  inflating: test_data/319945.jpeg   \n",
            "  inflating: __MACOSX/test_data/._319945.jpeg  \n",
            "  inflating: test_data/79963.jpeg    \n",
            "  inflating: __MACOSX/test_data/._79963.jpeg  \n",
            "  inflating: test_data/949956.jpeg   \n",
            "  inflating: __MACOSX/test_data/._949956.jpeg  \n",
            "  inflating: test_data/899886.jpeg   \n",
            "  inflating: __MACOSX/test_data/._899886.jpeg  \n",
            "  inflating: test_data/889886.jpeg   \n",
            "  inflating: __MACOSX/test_data/._889886.jpeg  \n",
            "  inflating: test_data/309928.jpeg   \n",
            "  inflating: __MACOSX/test_data/._309928.jpeg  \n",
            "  inflating: test_data/839998.jpeg   \n",
            "  inflating: __MACOSX/test_data/._839998.jpeg  \n",
            "  inflating: test_data/829920.jpeg   \n",
            "  inflating: __MACOSX/test_data/._829920.jpeg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_tsnojWGUQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c49a8c-4c69-458e-97df-0015de7495c2"
      },
      "source": [
        "# ディレクトリ内のデータの確認\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adc.json  \u001b[0m\u001b[01;34m__MACOSX\u001b[0m/     sample_submission.csv  test_data.zip  train_data.zip\n",
            "\u001b[01;34mdrive\u001b[0m/    \u001b[01;34msample_data\u001b[0m/  \u001b[01;34mtest_data\u001b[0m/             train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JW1Xc0arjIYy",
        "outputId": "310d2796-d517-4d0f-d943-246b492dfdb6"
      },
      "source": [
        "# Googleドライブのマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPlIpaNDZxsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "782b7237-ecd3-4a33-c60e-c610648933d4"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn, optim\n",
        "\n",
        "'''\n",
        "定数の指定\n",
        "'''\n",
        "\n",
        "# 学習済みパラメータのパス\n",
        "model_path = '/content/drive/My Drive/Colab Notebooks/SIGNATE/casting_pytorch/model/casting_pytorch_fine-tuning_Epoch156_logloss_0.0001.pth'\n",
        "\n",
        "# 提出データの保存先\n",
        "submit_path = '/content/drive/My Drive/Colab Notebooks/SIGNATE/casting_pytorch/submit/casting_pytorch_mobilenet_v3_ver1.csv'\n",
        "\n",
        "# 学習データのラベルマスター\n",
        "test_labels = './sample_submission.csv'\n",
        "sample_submit = './sample_submission.csv'\n",
        "\n",
        "# 画像データのディレクトリ\n",
        "img_dir = './test_data/'\n",
        "\n",
        "# リサイズする画像サイズ\n",
        "photo_size = 300\n",
        "\n",
        "# クラス数の定義\n",
        "num_classes = 2\n",
        "\n",
        "# 学習に使用する機器(device)の設定\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'デバイス：{device}')\n",
        "\n",
        "'''\n",
        "学習済みパラメータの読み込み\n",
        "'''\n",
        "\n",
        "model = models.mobilenet_v3_large(pretrained=False)\n",
        "fc_in_features = model.classifier[3].out_features # 最終レイヤー関数の次元数\n",
        "model.fc = nn.Linear(fc_in_features, num_classes) # 最終レイヤー関数の付け替え\n",
        "print(model)\n",
        "\n",
        "# モデルをGPUに送る\n",
        "model.to(device)\n",
        "\n",
        "# 学習済みパラメータの読み込み\n",
        "trained_params = torch.load(model_path)\n",
        "\n",
        "# モデルにパラメータをロード\n",
        "model.load_state_dict(trained_params)\n",
        "\n",
        "'''\n",
        "データの読み込み\n",
        "'''\n",
        "\n",
        "# ラベルデータの読み込み\n",
        "test_labels = pd.read_csv(test_labels, header=None, sep=',')\n",
        "print(test_labels.head())\n",
        "\n",
        "# 画像データの名前リストの抽出\n",
        "x_test = test_labels[0].values\n",
        "dummy = test_labels[0].values\n",
        "\n",
        "'''\n",
        "前処理とデータセットの作成\n",
        "'''\n",
        "\n",
        "# transformの設定\n",
        "transform = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(photo_size),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(photo_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ]),\n",
        "}\n",
        "\n",
        "# Datasetの設定\n",
        "class CastingDataset(Dataset):\n",
        "    def __init__(self, image_name_list, label_list, img_dir, phase=None):\n",
        "        self.image_name_list = image_name_list # 画像ファイル名\n",
        "        self.label_list = label_list # ラベル\n",
        "        self.img_dir = img_dir # 画像データのディレクトリ\n",
        "        self.phase = phase # 変数phaseで学習(train)もしくは検証(val)の設定を行う\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_name_list) # 1エポックあたりに読み込むデータ数として、入力データの数を指定\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        # index番目の画像を読み込み、前処理を行う\n",
        "        image_path = os.path.join(self.img_dir, self.image_name_list[index]) # train_master.iloc[index, 0]はファイル名を抽出\n",
        "        img = Image.open(image_path)\n",
        "        img = self.transform[self.phase](img)\n",
        "        \n",
        "        # index番目のラベルを取得する\n",
        "        label = self.label_list[index]\n",
        "        \n",
        "        return img, label\n",
        "\n",
        "# Datasetのインスタンス作成\n",
        "test_dataset = CastingDataset(x_test, dummy, img_dir, phase='val')\n",
        "\n",
        "# Dataloader\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "'''\n",
        "テストデータの予測\n",
        "'''\n",
        "\n",
        "# 予測データフレームの作成\n",
        "preds = []\n",
        "\n",
        "# dataloaderから、ミニバッチ単位でデータを読み込む\n",
        "for images, _ in test_dataloader:\n",
        "    \n",
        "    # 入力データをdeviceへ\n",
        "    images = images.to(device)\n",
        "    \n",
        "    # 学習済みモデルを推論モードに設定\n",
        "    model.eval()\n",
        "    \n",
        "    # モデルによる変換\n",
        "    outputs = model(images)\n",
        "    pred = torch.argmax(outputs, dim=1)\n",
        "    pred = pred.to('cpu').numpy()\n",
        "\n",
        "    # 予測値をリストに追加\n",
        "    preds.extend(pred)\n",
        "\n",
        "'''\n",
        "提出\n",
        "'''\n",
        "\n",
        "# 提出用データの読み込み\n",
        "sub = pd.read_csv(sample_submit, header=None, sep=',')\n",
        "print(sub.head())\n",
        "\n",
        "# 目的変数カラムの置き換え\n",
        "sub[1] = preds\n",
        "\n",
        "# ファイルのエクスポート\n",
        "sub.to_csv(submit_path, sep=',', header=None, index=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "デバイス：cuda\n",
            "MobileNetV3(\n",
            "  (features): Sequential(\n",
            "    (0): ConvNormActivation(\n",
            "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): Hardswish()\n",
            "    )\n",
            "    (1): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): ConvNormActivation(\n",
            "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): ConvNormActivation(\n",
            "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): ConvNormActivation(\n",
            "          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): ConvNormActivation(\n",
            "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (6): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): ConvNormActivation(\n",
            "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (7): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
            "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): ConvNormActivation(\n",
            "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (8): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
            "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): ConvNormActivation(\n",
            "          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (9): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
            "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): ConvNormActivation(\n",
            "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (10): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
            "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): ConvNormActivation(\n",
            "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (11): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
            "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): ConvNormActivation(\n",
            "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (12): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): ConvNormActivation(\n",
            "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (13): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
            "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): ConvNormActivation(\n",
            "          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (14): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): ConvNormActivation(\n",
            "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (15): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): ConvNormActivation(\n",
            "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (16): ConvNormActivation(\n",
            "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): Hardswish()\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=960, out_features=1280, bias=True)\n",
            "    (1): Hardswish()\n",
            "    (2): Dropout(p=0.2, inplace=True)\n",
            "    (3): Linear(in_features=1280, out_features=1000, bias=True)\n",
            "  )\n",
            "  (fc): Linear(in_features=1000, out_features=2, bias=True)\n",
            ")\n",
            "            0  1\n",
            "0  19871.jpeg  0\n",
            "1  29934.jpeg  0\n",
            "2  39826.jpeg  0\n",
            "3  49888.jpeg  0\n",
            "4  59918.jpeg  0\n",
            "            0  1\n",
            "0  19871.jpeg  0\n",
            "1  29934.jpeg  0\n",
            "2  39826.jpeg  0\n",
            "3  49888.jpeg  0\n",
            "4  59918.jpeg  0\n"
          ]
        }
      ]
    }
  ]
}